{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08aafab7",
   "metadata": {},
   "source": [
    "## Run the inference with the PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3778db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import lightglue_dynamo.models.superpoint_pytorch as superpoint_pytorch\n",
    "\n",
    "detection_thresh = 0.005\n",
    "nms_radius = 5\n",
    "max_keypoints = 256\n",
    "\n",
    "sp_th = superpoint_pytorch.SuperPointOpen(detection_threshold=detection_thresh, nms_radius=nms_radius, max_num_keypoints=max_keypoints).eval()\n",
    "print('Config:', sp_th.conf)\n",
    "\n",
    "# Load state dict (map_location=\"cpu\" if no GPU)\n",
    "ckpt = torch.load(\"/home/nvidia/third_party/LightGlue-ONNX-Jetson/weights/superpoint_v6_from_tf.pth\", map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Some checkpoints may be wrapped in {\"state_dict\": ...}\n",
    "if \"state_dict\" in ckpt:\n",
    "    ckpt = ckpt[\"state_dict\"]\n",
    "\n",
    "# Load weights\n",
    "sp_th.load_state_dict(ckpt, strict=True)\n",
    "sp_th.eval().cuda()\n",
    "# sp_th = torch.compile(sp_th, mode=\"reduce-overhead\")  # \"max-autotune\" , \"reduce-overhead\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c06666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from lightglue_dynamo.preprocessors import SuperPointOpenPreprocessor\n",
    "from lightglue_dynamo import viz\n",
    "\n",
    "# --- 1. Load and Normalize Images Individually ---\n",
    "image_path1 = '/home/nvidia/third_party/LightGlue-ONNX-Jetson/assets/debug1.png'\n",
    "image_path2 = '/home/nvidia/third_party/LightGlue-ONNX-Jetson/assets/debug2.png'\n",
    "\n",
    "h, w = 400, 640 \n",
    "\n",
    "# Load color images and resize them\n",
    "raw_img1 = cv2.resize(cv2.imread(image_path1), (w, h))\n",
    "raw_img2 = cv2.resize(cv2.imread(image_path2), (w, h))\n",
    "image_batch_bgr = np.stack([raw_img1, raw_img2], axis=0)\n",
    "preprocessed_batch = SuperPointOpenPreprocessor.preprocess(image_batch_bgr)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tensor = torch.from_numpy(preprocessed_batch).to(device)\n",
    "\n",
    "print(f\"Final tensor shape: {tensor.shape}\") #torch.Size([2, 1, H_padded, W_padded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd78be4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred = sp_th({\"image\": tensor})\n",
    "\n",
    "kpts = pred['keypoints'].cpu().numpy()\n",
    "scores = pred['keypoint_scores'].cpu().numpy()\n",
    "descriptors = pred['descriptors'].cpu().numpy()\n",
    "num_kpts = pred['num_keypoints'].cpu().numpy()\n",
    "\n",
    "print(f\"Keypoints: {kpts.shape}\")\n",
    "print(f\"Keypoint scores: {scores.shape}\")\n",
    "print(f\"Descriptors: {descriptors.shape}\")\n",
    "print(f\"Number of keypoints: {num_kpts.shape}\")\n",
    "\n",
    "viz.plot_sp_open(image_batch_bgr, image_batch_bgr.shape[0], kpts, num_kpts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d431ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "onnx_model_path = '/home/nvidia/third_party/LightGlue-ONNX-Jetson/weights/superpoint_open_b2_h400_w640_kp256.onnx'\n",
    "session = ort.InferenceSession(onnx_model_path, providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_names = [output.name for output in session.get_outputs()]\n",
    "print(f\"Input Name: {input_name}\")\n",
    "print(f\"Output Names: {output_names}\")\n",
    "\n",
    "# Run Inference\n",
    "onnx_inputs = {input_name: preprocessed_batch}\n",
    "print(\"Preprocessed batch:\", preprocessed_batch.shape, preprocessed_batch.dtype,\n",
    "      preprocessed_batch.min(), preprocessed_batch.max())\n",
    "\n",
    "outputs_onnx = session.run(output_names, onnx_inputs)\n",
    "\n",
    "# Unpack the list of outputs\n",
    "kpts_onnx, scores_onnx, desc_onnx, num_kpts_onnx = outputs_onnx\n",
    "\n",
    "print(\"\\n--- ONNX Runtime Output ---\")\n",
    "print(f\"Keypoints shape: {kpts_onnx.shape}\")\n",
    "print(f\"Scores shape: {scores_onnx.shape}\")\n",
    "print(f\"Descriptors shape: {desc_onnx.shape}\")\n",
    "print(f\"Num Keypoints: {num_kpts_onnx}\")\n",
    "print(\"Num keypoints (ONNX):\", num_kpts_onnx)\n",
    "print(\"Num keypoints (sum):\", sum(num_kpts_onnx) if num_kpts_onnx.ndim > 0 else num_kpts_onnx)\n",
    "\n",
    "viz.plot_sp_open(image_batch_bgr, image_batch_bgr.shape[0], kpts_onnx, num_kpts_onnx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightglue-onnx-py3.10 (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
