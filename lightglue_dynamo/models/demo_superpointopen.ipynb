{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08aafab7",
   "metadata": {},
   "source": [
    "## Run the inference with the PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3778db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import lightglue_dynamo.models.superpoint_pytorch as superpoint_pytorch\n",
    "\n",
    "detection_thresh = 0.005\n",
    "nms_radius = 5\n",
    "max_keypoints = 256\n",
    "\n",
    "sp_th = superpoint_pytorch.SuperPointOpen(detection_threshold=detection_thresh, nms_radius=nms_radius, max_num_keypoints=max_keypoints).eval()\n",
    "print('Config:', sp_th.conf)\n",
    "\n",
    "# Load state dict (map_location=\"cpu\" if no GPU)\n",
    "ckpt = torch.load(\"/home/nvidia/third_party/LightGlue-ONNX-Jetson/weights/superpoint_v6_from_tf.pth\", map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Some checkpoints may be wrapped in {\"state_dict\": ...}\n",
    "if \"state_dict\" in ckpt:\n",
    "    ckpt = ckpt[\"state_dict\"]\n",
    "\n",
    "# Load weights\n",
    "sp_th.load_state_dict(ckpt, strict=True)\n",
    "sp_th.eval().cuda()\n",
    "# sp_th = torch.compile(sp_th, mode=\"reduce-overhead\")  # \"max-autotune\" , \"reduce-overhead\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c06666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from lightglue_dynamo.preprocessors import SuperPointOpenPreprocessor\n",
    "from lightglue_dynamo import viz\n",
    "\n",
    "# --- 1. Load and Normalize Images Individually ---\n",
    "image_path1 = '/home/nvidia/third_party/LightGlue-ONNX-Jetson/assets/sacre_coeur1.jpg' # sacre_coeur1.jpg, debug1.png\n",
    "image_path2 = '/home/nvidia/third_party/LightGlue-ONNX-Jetson/assets/sacre_coeur2.jpg' # sacre_coeur2.jpg, debug2.png\n",
    "\n",
    "h, w = 400, 640 \n",
    "\n",
    "# Load color images and resize them\n",
    "raw_img1 = cv2.resize(cv2.imread(image_path1), (w, h))\n",
    "raw_img2 = cv2.resize(cv2.imread(image_path2), (w, h))\n",
    "image_batch_bgr = np.stack([raw_img1, raw_img2], axis=0)\n",
    "preprocessed_batch = SuperPointOpenPreprocessor.preprocess(image_batch_bgr)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tensor = torch.from_numpy(preprocessed_batch).to(device)\n",
    "\n",
    "print(f\"Final tensor shape: {tensor.shape}\") #torch.Size([2, 1, H_padded, W_padded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd78be4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred = sp_th({\"image\": tensor})\n",
    "\n",
    "kpts = pred['keypoints'].cpu().numpy()\n",
    "scores = pred['keypoint_scores'].cpu().numpy()\n",
    "descriptors = pred['descriptors'].cpu().numpy()\n",
    "num_kpts = pred['num_keypoints'].cpu().numpy()\n",
    "\n",
    "print(f\"Keypoints: {kpts.shape}\")\n",
    "print(f\"Keypoint scores: {scores.shape}\")\n",
    "print(f\"Descriptors: {descriptors.shape}\")\n",
    "print(f\"Number of keypoints: {num_kpts.shape}\")\n",
    "\n",
    "viz.plot_sp_open(image_batch_bgr, image_batch_bgr.shape[0], kpts, num_kpts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d431ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "onnx_model_path = '/home/nvidia/third_party/LightGlue-ONNX-Jetson/weights/superpoint_open_b2_h400_w640_kp256.onnx'\n",
    "session = ort.InferenceSession(onnx_model_path, providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_names = [output.name for output in session.get_outputs()]\n",
    "print(f\"Input Name: {input_name}\")\n",
    "print(f\"Output Names: {output_names}\")\n",
    "\n",
    "# Run Inference\n",
    "onnx_inputs = {input_name: preprocessed_batch}\n",
    "print(\"Preprocessed batch:\", preprocessed_batch.shape, preprocessed_batch.dtype,\n",
    "      preprocessed_batch.min(), preprocessed_batch.max())\n",
    "\n",
    "outputs_onnx = session.run(output_names, onnx_inputs)\n",
    "\n",
    "# Unpack the list of outputs\n",
    "kpts_onnx, scores_onnx, desc_onnx, num_kpts_onnx = outputs_onnx\n",
    "\n",
    "print(\"\\n--- ONNX Runtime Output ---\")\n",
    "print(f\"Keypoints shape: {kpts_onnx.shape}\")\n",
    "print(f\"Scores shape: {scores_onnx.shape}\")\n",
    "print(f\"Descriptors shape: {desc_onnx.shape}\")\n",
    "print(f\"Num Keypoints: {num_kpts_onnx}\")\n",
    "print(\"Num keypoints (ONNX):\", num_kpts_onnx)\n",
    "print(\"Num keypoints (sum):\", sum(num_kpts_onnx) if num_kpts_onnx.ndim > 0 else num_kpts_onnx)\n",
    "\n",
    "viz.plot_sp_open(image_batch_bgr, image_batch_bgr.shape[0], kpts_onnx, num_kpts_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a7a8d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72188/4138486542.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(\"/home/nvidia/third_party/LightGlue-ONNX-Jetson/weights/superpoint_v6_from_tf.pth\", map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PyTorch (reference) ===\n",
      "Keypoints: (2, 256, 2), range: [8.000, 632.000]\n",
      "Scores: (2, 256), range: [1.000, 1.000]\n",
      "Descriptors: (2, 256, 256), range: [-0.160, 0.152]\n",
      "Num keypoints: [256 256]\n",
      "\n",
      "=== ONNX ===\n",
      "Keypoints: (2, 256, 2), range: [4.000, 632.000]\n",
      "Scores: (2, 256), range: [1.000, 1.000]\n",
      "Descriptors: (2, 256, 256), range: [-0.145, 0.160]\n",
      "Num keypoints: [256 256]\n",
      "\n",
      "=== Differences ===\n",
      "Max keypoint diff: 592.000000\n",
      "Max score diff: 0.000000\n",
      "Max descriptor diff: 0.161384\n",
      "Max num_keypoints diff: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "def validate_export():\n",
    "    \"\"\"Run this right after your export to validate it matches PyTorch\"\"\"\n",
    "    \n",
    "    # Load your model exactly like in the export\n",
    "    from lightglue_dynamo.models.superpoint_pytorch import SuperPointOpen\n",
    "    \n",
    "    detection_thresh = 0.005\n",
    "    nms_radius = 5\n",
    "    max_keypoints = 256\n",
    "    \n",
    "    # Create model\n",
    "    extractor = SuperPointOpen(\n",
    "        detection_threshold=detection_thresh, \n",
    "        nms_radius=nms_radius, \n",
    "        max_num_keypoints=max_keypoints\n",
    "    )\n",
    "    \n",
    "    # Load same weights as export\n",
    "    ckpt = torch.load(\"/home/nvidia/third_party/LightGlue-ONNX-Jetson/weights/superpoint_v6_from_tf.pth\", map_location=\"cpu\")\n",
    "    if \"state_dict\" in ckpt:\n",
    "        ckpt = ckpt[\"state_dict\"]\n",
    "    \n",
    "    extractor.load_state_dict(ckpt, strict=True)\n",
    "    extractor.eval()\n",
    "    \n",
    "    # Same random seed as export\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    # Create test input\n",
    "    test_input = torch.randn(2, 1, 400, 640, dtype=torch.float32)\n",
    "    \n",
    "    # PyTorch inference\n",
    "    with torch.no_grad():\n",
    "        torch_output = extractor({\"image\": test_input})\n",
    "    \n",
    "    torch_kpts = torch_output[\"keypoints\"].numpy()\n",
    "    torch_scores = torch_output[\"keypoint_scores\"].numpy()\n",
    "    torch_desc = torch_output[\"descriptors\"].numpy()\n",
    "    torch_num = torch_output[\"num_keypoints\"].numpy()\n",
    "    \n",
    "    print(\"=== PyTorch (reference) ===\")\n",
    "    print(f\"Keypoints: {torch_kpts.shape}, range: [{torch_kpts.min():.3f}, {torch_kpts.max():.3f}]\")\n",
    "    print(f\"Scores: {torch_scores.shape}, range: [{torch_scores.min():.3f}, {torch_scores.max():.3f}]\")\n",
    "    print(f\"Descriptors: {torch_desc.shape}, range: [{torch_desc.min():.3f}, {torch_desc.max():.3f}]\")\n",
    "    print(f\"Num keypoints: {torch_num}\")\n",
    "    \n",
    "    # ONNX inference\n",
    "    onnx_path = '/home/nvidia/third_party/LightGlue-ONNX-Jetson/weights/superpoint_open_b2_h400_w640_kp256.onnx'\n",
    "    session = ort.InferenceSession(onnx_path, providers=['CPUExecutionProvider'])\n",
    "    \n",
    "    onnx_output = session.run(None, {\"images\": test_input.numpy()})\n",
    "    onnx_kpts, onnx_scores, onnx_desc, onnx_num = onnx_output\n",
    "    \n",
    "    print(\"\\n=== ONNX ===\")\n",
    "    print(f\"Keypoints: {onnx_kpts.shape}, range: [{onnx_kpts.min():.3f}, {onnx_kpts.max():.3f}]\")\n",
    "    print(f\"Scores: {onnx_scores.shape}, range: [{onnx_scores.min():.3f}, {onnx_scores.max():.3f}]\")\n",
    "    print(f\"Descriptors: {onnx_desc.shape}, range: [{onnx_desc.min():.3f}, {onnx_desc.max():.3f}]\")\n",
    "    print(f\"Num keypoints: {onnx_num}\")\n",
    "    \n",
    "    # Compare\n",
    "    print(\"\\n=== Differences ===\")\n",
    "    kpt_diff = np.max(np.abs(torch_kpts - onnx_kpts))\n",
    "    score_diff = np.max(np.abs(torch_scores - onnx_scores))\n",
    "    desc_diff = np.max(np.abs(torch_desc - onnx_desc))\n",
    "    num_diff = np.max(np.abs(torch_num - onnx_num))\n",
    "    \n",
    "    print(f\"Max keypoint diff: {kpt_diff:.6f}\")\n",
    "    print(f\"Max score diff: {score_diff:.6f}\")\n",
    "    print(f\"Max descriptor diff: {desc_diff:.6f}\")\n",
    "    print(f\"Max num_keypoints diff: {num_diff}\")\n",
    "\n",
    "validate_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightglue-onnx-py3.10 (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
